{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def switch_from_string_to_integer(mungchi_string):\n",
    "    # 슬래시와 공백을 제외한 글자 수를 계산\n",
    "    parts = mungchi_string.split('/')  # 슬래시를 기준으로 문자열을 나눔\n",
    "    mungchi_integer = [len(part.strip()) for part in parts]  # 각 부분을 공백 제거 후 길이 계산\n",
    "    return mungchi_integer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['title', 'genre', 'mungchi', 'output', 'instruction',\n",
      "       '__index_level_0__', 'lyrics'],\n",
      "      dtype='object')\n",
      "(47678, 7)\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"AcapeLlama/AcapeLlama_v2.0_test\", 'line')\n",
    "dataframe = pd.DataFrame(dataset['test'])\n",
    "print(dataframe.columns)\n",
    "print(dataframe.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dataframe.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Inference\n",
    "- 가상의 테스트셋에 해당하는 노래 10곡\n",
    "- 여기서 input으로 요청하는 음절수가 golden_mungchi_integer에 저장되어야 함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 7)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_test_df = df.sample(n=10, random_state=42)\n",
    "temp_test_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def switch_from_string_to_integer(mungchi_string):\n",
    "    # 슬래시와 공백을 제외한 글자 수를 계산\n",
    "    parts = mungchi_string.split('/')  # 슬래시를 기준으로 문자열을 나눔\n",
    "    mungchi_integer = [len(part.strip()) for part in parts]  # 각 부분을 공백 제거 후 길이 계산\n",
    "    return mungchi_integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "import similarity_metric as sm\n",
    "import formality_metric as fm\n",
    "\n",
    "def evaluation(golden_lyrics_list, golden_mungchi_integer_list, predict_mungchi_string_list, result_dir, sample_strategy):\n",
    "    predict_mungchi_integer_list = []\n",
    "    semantic_sim_list = []\n",
    "    lexical_sim_list = []\n",
    "    acc_form_list = []\n",
    "    mse_form_list = []\n",
    "    our_form_list = []\n",
    "\n",
    "    # 의미 유사도 산출을 위한 encoder 불러오기\n",
    "    model = AutoModel.from_pretrained(\"klue/roberta-base\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"klue/roberta-base\")\n",
    "\n",
    "    for golden_lyrics, golden_mungchi_integer, predict_mungchi_string in zip(golden_lyrics_list, golden_mungchi_integer_list, predict_mungchi_string_list):\n",
    "        \n",
    "        # switch from predict_mungchi string to integer\n",
    "        predict_mungchi_integer = switch_from_string_to_integer(predict_mungchi_string)\n",
    "        predict_mungchi_integer_list.append(predict_mungchi_integer)\n",
    "        \n",
    "        # evaluate test data\n",
    "        semantic_sim = sm.eval_semantic_sim(model, tokenizer, golden_lyrics, predict_mungchi_string)\n",
    "        lexical_sim = sm.eval_lexical_sim_precision(golden_lyrics, predict_mungchi_string)\n",
    "        acc_form, mse_form = fm.eval_form(golden_mungchi_integer, predict_mungchi_integer)\n",
    "        our_form = fm.eval_our_form(golden_mungchi_integer, predict_mungchi_integer)\n",
    "        \n",
    "        # save scores\n",
    "        semantic_sim_list.append(semantic_sim)\n",
    "        lexical_sim_list.append(lexical_sim)\n",
    "        acc_form_list.append(acc_form)\n",
    "        mse_form_list.append(mse_form)\n",
    "        our_form_list.append(our_form)\n",
    "\n",
    "    # create evaluation dataframe to matching with the original lyrics\n",
    "    eval_df = pd.DataFrame({'original_lyrics' : temp_test_df['lyrics'],\n",
    "                            'input_mungchi_integer' : golden_mungchi_integer_list,\n",
    "                            'generated_mungchi_string' : predict_mungchi_string_list,\n",
    "                            'generated_mungchi_integer' : predict_mungchi_integer_list,\n",
    "                            'semantic_sim' : semantic_sim_list,\n",
    "                            'lexical_sim' : lexical_sim_list,\n",
    "                            'acc_form' : acc_form_list,\n",
    "                            'mse_form' : mse_form_list,\n",
    "                            'our_form' : our_form_list})\n",
    "\n",
    "    # get average scores\n",
    "    keys_to_average = ['semantic_sim', 'lexical_sim', 'acc_form', 'mse_form', 'our_form']\n",
    "    averages_dict = {key: eval_df[key].mean() for key in keys_to_average}\n",
    "\n",
    "    # save evaluation result\n",
    "    eval_df.to_json(f'{result_dir}/eval_df.json', orient='records', lines=True)\n",
    "    return averages_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>genre</th>\n",
       "      <th>mungchi</th>\n",
       "      <th>output</th>\n",
       "      <th>instruction</th>\n",
       "      <th>__index_level_0__</th>\n",
       "      <th>lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15122</th>\n",
       "      <td>기대해도 좋은 날</td>\n",
       "      <td>댄스</td>\n",
       "      <td>[7]</td>\n",
       "      <td>기대해도 좋은 날</td>\n",
       "      <td>다음 조건에 어울리는 가사를 써주실 수 있나요? 주어진 음절 수를 절대 벗어나면 안...</td>\n",
       "      <td>415182</td>\n",
       "      <td>Woo Hoo\\nWoo Hoo Hoo Hoo\\nWoo Hoo Hoo Hoo\\n저기 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           title genre mungchi     output  \\\n",
       "15122  기대해도 좋은 날    댄스     [7]  기대해도 좋은 날   \n",
       "\n",
       "                                             instruction  __index_level_0__  \\\n",
       "15122  다음 조건에 어울리는 가사를 써주실 수 있나요? 주어진 음절 수를 절대 벗어나면 안...             415182   \n",
       "\n",
       "                                                  lyrics  \n",
       "15122  Woo Hoo\\nWoo Hoo Hoo Hoo\\nWoo Hoo Hoo Hoo\\n저기 ...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_test_df.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'semantic_sim': 0.97839755,\n",
       " 'lexical_sim': 1.0,\n",
       " 'acc_form': 0.3,\n",
       " 'mse_form': 4.8,\n",
       " 'our_form': 0.45}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "golden_lyrics_list = temp_test_df['lyrics'].tolist()\n",
    "golden_mungchi_integer_list = temp_test_df['mungchi'].tolist()\n",
    "predict_mungchi_string_list = temp_test_df['output'].tolist()\n",
    "result_dir = '/workspace/codes/evaluation'\n",
    "sample_strategy = 'line'\n",
    "    \n",
    "evaluation(golden_lyrics_list, golden_mungchi_integer_list, predict_mungchi_string_list, result_dir, sample_strategy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
